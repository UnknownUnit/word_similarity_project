{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Word Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Student Name: Jia Shun Low\n",
    "\n",
    "Student ID: 743436"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Due date</b>: Thursday, 18 Apr 2019 4pm\n",
    "\n",
    "<b>Submission method</b>: see LMS\n",
    "\n",
    "<b>Submission materials</b>: completed copy of this iPython notebook\n",
    "\n",
    "<b>Late submissions</b>: -20% per day\n",
    "\n",
    "<b>Marks</b>: 7% of mark for class (with 6% on correctness + 1% on quality and efficiency of your code)\n",
    "\n",
    "<b>Materials</b>: See the main class LMS page for information on the basic setup required for this class, including an iPython notebook viewer and the python packages NLTK, Numpy, Scipy, Matplotlib and Scikit-Learn. In particular, if you are not using a lab computer which already has it installed, we recommend installing all the data for NLTK, since you will need various parts of it to complete this assignment. You can also use any Python built-in packages, but do not use any other 3rd party packages; if your iPython notebook doesn't run on the marker's machine, you will lose marks. <b> You should use Python 3</b>. \n",
    "\n",
    "To familiarize yourself with NLTK, here is a free online book:  Steven Bird, Ewan Klein, and Edward Loper (2009). <a href=http://nltk.org/book>Natural Language Processing with Python</a>. O'Reilly Media Inc. You may also consult the <a href=https://www.nltk.org/api/nltk.html>NLTK API</a>.\n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). You should edit the sections below where requested, but leave the rest of the code as is. You should leave the output from running your code in the iPython notebook you submit, to assist with marking. The amount each section is worth is given in parenthesis after the instructions. \n",
    "\n",
    "You will be marked not only on the correctness of your methods, but also the quality and efficency of your code: in particular, you should be careful to use Python built-in functions and operators when appropriate and pick descriptive variable names that adhere to <a href=\"https://www.python.org/dev/peps/pep-0008/\">Python style requirements</a>. If you think it might be unclear what you are doing, you should comment your code to help the marker make sense of it.\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via LMS. Minor changes and clarifications will be announced in the forum on LMS, we recommend you check the forum regularly.\n",
    "\n",
    "<b>Academic Misconduct</b>: For most people, collaboration will form a natural part of the undertaking of this homework, and we encourge you to discuss it in general terms with other students. However, this ultimately is still an individual task, and so reuse of code or other instances of clear influence will be considered cheating. We will be checking submissions for originality and will invoke the Universityâ€™s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, you'll be quantifying the similarity between pairs of words of a dataset using different methods with the word co-occurrence in the Brown corpus and synset structure of WordNet. Firstly, you will preprocess the dataset to filter out the rare and ambiguous words. Secondly, you will calculate the similarity scores for pairs of words in the filtered dateset using Lin similarity, NPMI and LSA. Lastly, you will quantify how well these methods work by comparing to a human annotated gold-standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Instructions</b>: For this homework we will be comparing our methods against a popular dataset of word similarities called <a href=\"http://www.cs.technion.ac.il/~gabr/resources/data/wordsim353/\">Similarity-353</a>. You need to first obtain this dataset, which is available on LMS. The file we will be using is called *set1.tab*. Make sure you save this in the same folder as the notebook.  Except for the header (which should be stripped out), the file is tab formated with the first two columns corresponding to two words, and the third column representing a human-annotated similarity between the two words. <b>You should ignore the subsequent columns</b>.\n",
    "\n",
    "Here shows the first six lines of the file:\n",
    "\n",
    "```\n",
    "Word 1\tWord 2\tHuman (mean)\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\t13\t\n",
    "love\tsex\t6.77\t9\t6\t8\t8\t7\t8\t8\t4\t7\t2\t6\t7\t8\t\n",
    "tiger\tcat\t7.35\t9\t7\t8\t7\t8\t9\t8.5\t5\t6\t9\t7\t5\t7\t\n",
    "tiger\ttiger\t10.00\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t10\t\n",
    "book\tpaper\t7.46\t8\t8\t7\t7\t8\t9\t7\t6\t7\t8\t9\t4\t9\t\n",
    "computer\tkeyboard\t7.62\t8\t7\t9\t9\t8\t8\t7\t7\t6\t8\t10\t3\t9\t\n",
    "```\n",
    "    \n",
    "You should load this file into a Python dictionary (NOTE: in Python, tuples of strings, i.e. (\"tiger\",\"cat\") can serve as the keys of a dictionary to map to their human-annotated similarity). This dataset contains many rare words: we need to filter this dataset in order for it to be better suited to the resources we will use in this assignment. So your first goal is to filter this dataset to generate a smaller test set where you will evaluate your word similarity methods.\n",
    "\n",
    "The first filtering is based on document frequencies in the Brown corpus, in order to remove rare words. In this homework, we will be treating the paragraphs of the Brown corpus as our \"documents\". You can iterate over them by using the `paras` method of the corpus reader. You should remove tokens that are not alphabetic. Tokens should be lower-cased and lemmatized. Now calculate document frequencies for each word type, and use this to remove from your word similarity data any word pairs where at least one of the two words has a document frequency of less than 8 in this corpus.\n",
    "\n",
    "For this part, you should store all the word pair and similarity mappings in your filtered test set in a dictionary called *filtered_gold_standard*. You may check the section, <i>\"For your testing\"</i>, below for the expected *filtered_gold_standard*.\n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to C:\\Users\\Jia\n",
      "[nltk_data]     Shun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Jia\n",
      "[nltk_data]     Shun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "{('love', 'sex'): 6.77, ('tiger', 'cat'): 7.35, ('tiger', 'tiger'): 10.0, ('book', 'paper'): 7.46, ('plane', 'car'): 5.77, ('train', 'car'): 6.31, ('telephone', 'communication'): 7.5, ('television', 'radio'): 6.77, ('drug', 'abuse'): 6.85, ('bread', 'butter'): 6.19, ('doctor', 'nurse'): 7.0, ('professor', 'doctor'): 6.62, ('student', 'professor'): 6.81, ('smart', 'student'): 4.62, ('smart', 'stupid'): 5.81, ('company', 'stock'): 7.08, ('stock', 'market'): 8.08, ('stock', 'phone'): 1.62, ('stock', 'egg'): 1.81, ('stock', 'live'): 3.73, ('stock', 'life'): 0.92, ('book', 'library'): 7.46, ('bank', 'money'): 8.12, ('wood', 'forest'): 7.73, ('money', 'cash'): 9.08, ('king', 'queen'): 8.58, ('bishop', 'rabbi'): 6.69, ('holy', 'sex'): 1.62, ('football', 'basketball'): 6.81, ('football', 'tennis'): 6.63, ('tennis', 'racket'): 7.56, ('law', 'lawyer'): 8.38, ('movie', 'star'): 7.38, ('movie', 'critic'): 6.73, ('movie', 'theater'): 7.92, ('space', 'chemistry'): 4.88, ('alcohol', 'chemistry'): 5.54, ('drink', 'car'): 3.04, ('drink', 'ear'): 1.31, ('drink', 'mouth'): 5.96, ('drink', 'eat'): 6.87, ('baby', 'mother'): 7.85, ('drink', 'mother'): 2.65, ('car', 'automobile'): 8.94, ('journey', 'voyage'): 9.29, ('coast', 'shore'): 9.1, ('food', 'fruit'): 7.52, ('bird', 'cock'): 7.1, ('tool', 'implement'): 6.46, ('brother', 'monk'): 6.27, ('journey', 'car'): 5.85, ('coast', 'hill'): 4.38, ('forest', 'graveyard'): 1.85, ('monk', 'slave'): 0.92, ('coast', 'forest'): 3.15, ('chord', 'smile'): 0.54, ('noon', 'string'): 0.54, ('money', 'dollar'): 8.42, ('money', 'currency'): 9.04, ('money', 'wealth'): 8.27, ('money', 'property'): 7.57, ('money', 'possession'): 7.29, ('money', 'bank'): 8.5, ('money', 'deposit'): 7.73, ('money', 'operation'): 3.31, ('tiger', 'animal'): 7.0, ('tiger', 'organism'): 4.77, ('tiger', 'zoo'): 5.87, ('psychology', 'anxiety'): 7.0, ('psychology', 'fear'): 6.85, ('psychology', 'depression'): 7.42, ('psychology', 'doctor'): 6.42, ('psychology', 'mind'): 7.69, ('psychology', 'health'): 7.23, ('psychology', 'science'): 6.71, ('psychology', 'discipline'): 5.58, ('planet', 'star'): 8.45, ('planet', 'moon'): 8.08, ('planet', 'sun'): 8.02, ('planet', 'galaxy'): 8.11, ('planet', 'space'): 7.92, ('precedent', 'example'): 5.85, ('precedent', 'information'): 3.85, ('precedent', 'law'): 6.65, ('precedent', 'collection'): 2.5, ('precedent', 'group'): 1.77, ('cup', 'coffee'): 6.58, ('cup', 'article'): 2.4, ('cup', 'object'): 3.69, ('cup', 'entity'): 2.15, ('cup', 'drink'): 7.25, ('cup', 'food'): 5.0, ('cup', 'substance'): 1.92, ('cup', 'liquid'): 5.9}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download(\"brown\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# filtered_gold_standard stores the word pairs and their human-annotated similarity in your filtered test set\n",
    "filtered_gold_standard = {}\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "\n",
    "# some constants.\n",
    "RARE_THRESHOLD = 8\n",
    "\n",
    "# We need to create a dictionary of token to doc freq.\n",
    "\n",
    "# We  create a list of sets, of lemmatized words. Each set represents a paragraph\n",
    "# from brown.paras(), and contains all the words that are alphabetical in lowercase and lemmatized\n",
    "# form. When we encounter a new token, we add it to our dictionary with initial value 0.\n",
    "# At the end of adding each paragraph as a set, we then update the doc_freq counts in the \n",
    "# dictionary.\n",
    "\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "# this function performs the appropriate lemmatization of the words in brown corpus.\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "doc_freq_dict = {}\n",
    "for para in brown.paras():\n",
    "    \n",
    "    # for every paragraph in .paras(), we have a list of sublist, \n",
    "    # each sublist being a sentence. We have to flatten the list\n",
    "    # so we have a list of all words in the paragraph.\n",
    "    para_set = set()\n",
    "    paragraph_words = []\n",
    "    for sentence in para:\n",
    "        for word in sentence:\n",
    "            paragraph_words.append(word) \n",
    "    \n",
    "    # After flattening, we go through each word, check if .isalpha(), \n",
    "    # then we lowercase and lemmatize it.\n",
    "    for word in paragraph_words:\n",
    "        if word.isalpha():\n",
    "            processed_word = lemmatize(word.lower())\n",
    "            para_set.add(processed_word)\n",
    "            \n",
    "            # if after preprocessing, we have never seen the word before, we add\n",
    "            # it to the frequency dictionary, with initial value 0, because all \n",
    "            # updates to the value happen at the end of the outer for loop.\n",
    "            if processed_word not in doc_freq_dict:\n",
    "                doc_freq_dict[processed_word] = 0\n",
    "    \n",
    "    # now that we have a set of preprocessed words that occured in this paragraph, \n",
    "    # we can go through all the keys we have and increase the doc_freq by 1 if \n",
    "    # the word occured.\n",
    "    for key in doc_freq_dict:\n",
    "        if key in para_set:\n",
    "            doc_freq_dict[key] += 1\n",
    "\n",
    "\n",
    "# now, we begin to populate filtered_gold_standard only with entries that pass the rarity\n",
    "# test. \n",
    "\n",
    "# we get every line by splitting by the newline character.\n",
    "\n",
    "filename = 'set1.tab'\n",
    "s = open(filename, 'r').read()\n",
    "lines = s.split('\\n')\n",
    "\n",
    "# for every line in the set1 file, we take out the first to remove header, and the \n",
    "# last because it does not contain useful information and is a by product of splitting\n",
    "# by the newline character.\n",
    "for line in lines[1:-1]:\n",
    "    # we take the first 3 elements of a list split by tab character, \n",
    "    # to obtain word 1, word 2 to create a tuple that will be the key, and some\n",
    "    # similarity which will be the value in filtered_gold_standard\n",
    "    line_elements = line.split('\\t')\n",
    "    w1 = line_elements[0]\n",
    "    w2 = line_elements[1]\n",
    "\n",
    "    if w1 in doc_freq_dict and w2 in doc_freq_dict:\n",
    "        if doc_freq_dict[w1] >= RARE_THRESHOLD and doc_freq_dict[w2] >= RARE_THRESHOLD:\n",
    "            sim_score = float(line_elements[2])\n",
    "            filtered_gold_standard[(w1,w2)] = sim_score          \n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "print(len(filtered_gold_standard))\n",
    "print(filtered_gold_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For your testing: </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(filtered_gold_standard) > 50 and len(filtered_gold_standard) < 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(filtered_gold_standard[('love', 'sex')] == 6.77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Instructions</b>: Here, you apply the second filtering. The second filtering is based on words with highly ambiguous senses and involves using the NLTK interface to WordNet. Here, you should remove any words which do not have a *single primary sense*. We define single primary sense here as either a) having only one sense (i.e. only one synset), or b) where the count (as provided by the WordNet `count()` method for the lemmas associated with a synset) of the most common sense is at least 4 times larger than the next most common sense. Note that a synset can be associated with multiple lemmas. You should only consider the count of your lemma. Also, you should remove any words where the primary sense is not a noun (this information is also in the synset). Store the synset corresponding to this primary sense in a dictionary for use in the next section. Given this definition, remove the word pairs from the test set where at least one of the words does not meet the above criteria.\n",
    "\n",
    "When you have applied the two filtering steps, you should store all the word pair and similarity mappings in your filtered test set in a dictionary called *final_gold_standard*. You may check the section, <i>\"For your testing\"</i>, below for the expected *final_gold_standard*.\n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "{('bread', 'butter'): 6.19, ('professor', 'doctor'): 6.62, ('student', 'professor'): 6.81, ('stock', 'egg'): 1.81, ('money', 'cash'): 9.08, ('king', 'queen'): 8.58, ('bishop', 'rabbi'): 6.69, ('football', 'basketball'): 6.81, ('football', 'tennis'): 6.63, ('alcohol', 'chemistry'): 5.54, ('baby', 'mother'): 7.85, ('car', 'automobile'): 8.94, ('journey', 'voyage'): 9.29, ('coast', 'shore'): 9.1, ('brother', 'monk'): 6.27, ('journey', 'car'): 5.85, ('coast', 'hill'): 4.38, ('forest', 'graveyard'): 1.85, ('monk', 'slave'): 0.92, ('coast', 'forest'): 3.15, ('psychology', 'doctor'): 6.42, ('psychology', 'mind'): 7.69, ('psychology', 'health'): 7.23, ('psychology', 'science'): 6.71, ('planet', 'moon'): 8.08, ('planet', 'galaxy'): 8.11}\n"
     ]
    }
   ],
   "source": [
    "# final_gold_standard stores the word pairs and their human-annotated similarity in your final filtered test set\n",
    "final_gold_standard = {}\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "\n",
    "# we take our filtered_gold_standard, and keep the words that have a single primary sense\n",
    "# defined as having only one synset, OR the count of the most common sense is at least \n",
    "# 4 times larger than the next most common sense.\n",
    "# we should also remove any word where the primary sense is not a noun, however our data set\n",
    "# only contains nouns.\n",
    "def one_primary_sense(word):\n",
    "    # get the synsets for that word.\n",
    "    synsets = wordnet.synsets(word)\n",
    "    primary_sense = None\n",
    "    if len(synsets) == 1:\n",
    "        return True\n",
    "\n",
    "    # if we have more than one synset, we now check for the second condition, \n",
    "    # that the most common count is at least 4 times larger\n",
    "    # than the second most common count. We only do this for lemmas that match our lemma exactly.\n",
    "    # we first obtain all the lemman counts.\n",
    "    else:\n",
    "        synset_common_count = []\n",
    "        for synset in synsets:\n",
    "            for lemma in synset.lemmas():\n",
    "                if lemma.name().lower() == word:\n",
    "                    synset_common_count.append(lemma.count())\n",
    "    \n",
    "    # if, after getting the counts for the lemmas which match our word, we don't even have\n",
    "    # 2, then the word does not have one sense.\n",
    "    if len(synset_common_count) < 2:\n",
    "        return False\n",
    "    \n",
    "    # if we have more than 2 lemma counts, then we can do the at least 4 times more comparision \n",
    "    # between most common and second most common\n",
    "    synset_common_count.sort()\n",
    "    most_common_count = synset_common_count[-1]\n",
    "    second_most_common_count = synset_common_count[-2]\n",
    "    return second_most_common_count*4 <= most_common_count \n",
    "\n",
    "# now we construct a new dictionary with only pairs where both words have one primary sense\n",
    "for w1,w2 in filtered_gold_standard:\n",
    "    if one_primary_sense(w1) and one_primary_sense(w2):\n",
    "        final_gold_standard[(w1,w2)] = filtered_gold_standard[(w1,w2)]\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "print(len(final_gold_standard))\n",
    "print(final_gold_standard)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(final_gold_standard) > 10 and len(final_gold_standard) < 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(final_gold_standard[('professor', 'doctor')] == 6.62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word similiarity scores with Lin similarity, NPMI and LSA (3 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Instructions</b>: Now you will create several dictionaries with similarity scores for pairs of words in your test set derived using the techniques discussed in class. The first of these is the Lin similarity for your word pairs using the information content of the Brown corpus, which you should calculate using the primary sense for each word derived above. You can use the built-in method included in the NLTK interface, you don't have to implement your own. \n",
    "\n",
    "When you're done, you should store the word pair and similarity mappings in a dictionary called *lin_similarities*. You may check the section, <i>\"For your testing\"</i>, below for the expected *lin_similarities*. \n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet_ic to C:\\Users\\Jia\n",
      "[nltk_data]     Shun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('bread', 'butter'): 0.711420490146294, ('professor', 'doctor'): 0.7036526610448273, ('student', 'professor'): 0.26208607023317687, ('stock', 'egg'): -0.0, ('money', 'cash'): 0.7888839126424345, ('king', 'queen'): 0.25872135992145145, ('bishop', 'rabbi'): 0.6655650900427844, ('football', 'basketball'): 0.7536025025710653, ('football', 'tennis'): 0.7699955045932811, ('alcohol', 'chemistry'): 0.062235427146896456, ('baby', 'mother'): 0.6315913189894092, ('car', 'automobile'): 1.0, ('journey', 'voyage'): 0.6969176573027711, ('coast', 'shore'): 0.9632173804623256, ('brother', 'monk'): 0.24862817480738675, ('journey', 'car'): -0.0, ('coast', 'hill'): 0.5991131628821826, ('forest', 'graveyard'): -0.0, ('monk', 'slave'): 0.2543108201944307, ('coast', 'forest'): -0.0, ('psychology', 'doctor'): -0.0, ('psychology', 'mind'): 0.304017384194818, ('psychology', 'health'): 0.06004979886905243, ('psychology', 'science'): 0.8474590505736942, ('planet', 'moon'): 0.14532306834462655, ('planet', 'galaxy'): -0.0}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet_ic\n",
    "nltk.download('wordnet_ic')\n",
    "\n",
    "# lin_similarities stores the word pair and Lin similarity mappings\n",
    "lin_similarities = {}\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "\n",
    "# Given a word with more than one synset, we want to get the most common synset.\n",
    "def get_most_common_synset(word, synsets):\n",
    "    max_count = 0\n",
    "    most_common_synset = None\n",
    "    for synset in synsets:\n",
    "        for lemma in synset.lemmas():\n",
    "            if lemma.name() == word:\n",
    "                if lemma.count() >= max_count:\n",
    "                    max_count = lemma.count()\n",
    "                    most_common_synset = synset\n",
    "    return most_common_synset\n",
    "\n",
    "# Given a word, we want to get a synset for calculating lin similarity.\n",
    "# If it just has one synset, then we take that, otherwise we have to \n",
    "# get the most common synset. We assume these words just have one sense, \n",
    "# as they have been filterd from cell above.\n",
    "def get_synset_for_lin(word):\n",
    "    synsets = wordnet.synsets(word, 'n')\n",
    "    if len(synsets) == 1:\n",
    "        return synsets[0]\n",
    "    else:\n",
    "        return get_most_common_synset(word, synsets)\n",
    "\n",
    "# calculates lin_similarity between 2 words, in this notebook we only use\n",
    "# brown ic, but this function works in general for all ic.\n",
    "def calculate_lin_similarity(w1, w2, brown_ic):\n",
    "    # first we get the synset of w1, and the synset of word 2\n",
    "    synset_w1 = get_synset_for_lin(w1)\n",
    "    synset_w2 = get_synset_for_lin(w2)\n",
    "    return synset_w1.lin_similarity(synset_w2, brown_ic) \n",
    "\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "# construct lin similarities dicitonary\n",
    "for key in final_gold_standard:\n",
    "    w1,w2 = key\n",
    "    lin_similarities[key] = calculate_lin_similarity(w1,w2, brown_ic)\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "print(lin_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(lin_similarities[('professor', 'doctor')] > 0.5 and lin_similarities[('professor', 'doctor')] < 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** Next, you will calculate Normalized PMI (NPMI) for your word pairs using word frequency derived from the Brown.\n",
    "\n",
    "PMI is defined as:\n",
    "\n",
    "\\begin{equation*}\n",
    "PMI = \\log_2\\left(\\frac{p(x,y)}{p(x)p(y)}\\right)\n",
    "\\end{equation*}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{equation*}\n",
    "p(x,y) = \\frac{\\text{Number of paragraphs with the co-occurrence of x and y}}{\\sum_i \\text{Number of word types in paragraph}_i}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "p(x) = \\frac{\\text{Number of paragraphs with the occurrence of x}}{\\sum_i \\text{Number of word types in paragraph}_i}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "p(y) = \\frac{\\text{Number of paragraphs with the occurrence of y}}{\\sum_i \\text{Number of word types in paragraph}_i}\n",
    "\\end{equation*}\n",
    "\n",
    "with the sum over $i$ ranging over all paragraphs. Note that there are other ways PMI could be formulated.\n",
    "\n",
    "NPMI is defined as:\n",
    "\n",
    "\\begin{equation*}\n",
    "NPMI = \\frac{PMI}{-\\log_2(p(x,y))} = \\frac{\\log_2(p(x)p(y))}{\\log_2(p(x,y))} - 1\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, when there is no co-occurrence, NPMI is -1. NPMI is normalized between [-1, +1].\n",
    "\n",
    "You should use the same set up as you did to calculate document frequency above: paragraphs as documents, lemmatized, lower-cased, and with term frequency information removed by conversion to Python sets. You need to use the basic method for calculating PMI introduced in class (and also in the reading) which is appropriate for any possible definition of co-occurrence (here, there is co-occurrence when a word pair appears in the same paragraph), but you should only calculate PMI for the words in your test set. You must avoid building the entire co-occurrence matrix, instead you should keeping track of the sums you need for the probabilities as you go along. \n",
    "\n",
    "When you have calculated NPMI for all the pairs, you should store the word pair and NPMI-similarity mappings in a dictionary called *NPMI_similarities*. You may check the section, <i>\"For your testing\"</i>, below for the expected *NPMI_similarities*. \n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('bread', 'butter'): 0.675770944127283, ('professor', 'doctor'): -1, ('student', 'professor'): -1, ('stock', 'egg'): -1, ('money', 'cash'): 0.4444037486658723, ('king', 'queen'): 0.5120636847952567, ('bishop', 'rabbi'): -1, ('football', 'basketball'): 0.69758913584575, ('football', 'tennis'): -1, ('alcohol', 'chemistry'): -1, ('baby', 'mother'): 0.3924720350043247, ('car', 'automobile'): 0.4321828806781993, ('journey', 'voyage'): -1, ('coast', 'shore'): -1, ('brother', 'monk'): -1, ('journey', 'car'): -1, ('coast', 'hill'): -1, ('forest', 'graveyard'): -1, ('monk', 'slave'): -1, ('coast', 'forest'): -1, ('psychology', 'doctor'): -1, ('psychology', 'mind'): -1, ('psychology', 'health'): -1, ('psychology', 'science'): -1, ('planet', 'moon'): 0.7145517939077397, ('planet', 'galaxy'): -1}\n"
     ]
    }
   ],
   "source": [
    "# NPMI_similarities stores the word pair and NPMI similarity mappings\n",
    "NPMI_similarities = {}\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "import math\n",
    "\n",
    "# Function that takes in the brown corpus, and returns\n",
    "# a list of sets, each set corresponding to the words in a paragraph.\n",
    "def create_brown_list(brown):\n",
    "    brown_list = []\n",
    "    for para in brown.paras():\n",
    "        para_set = set()\n",
    "        for word in para[0]:\n",
    "            if word.isalpha():\n",
    "                processed_word = lemmatize(word.lower())\n",
    "                para_set.add(processed_word)\n",
    "        brown_list.append(para_set)\n",
    "    return brown_list\n",
    "\n",
    "# calculates numerator for the p(x) and p(y) functions in NPMI.\n",
    "def calculate_p_word_numerator(word, brown_list):\n",
    "    numerator = 0\n",
    "    for para in brown_list:\n",
    "        if word in para:\n",
    "            numerator += 1\n",
    "    return numerator\n",
    "\n",
    "# calculates the numerator for p(x,y) function in NPMI\n",
    "def calculate_p_cooccurrence_numerator(word1, word2, brown_list):\n",
    "    numerator = 0\n",
    "    for para in brown_list:\n",
    "        if word1 in para and word2 in para:\n",
    "            numerator += 1\n",
    "    return numerator\n",
    "\n",
    "# calcualtes the denominator for p(x) and p(x,y) functions in NPMI.\n",
    "def calculate_p_denominator(brown_list):\n",
    "    denominator = 0\n",
    "    for para in brown_list:\n",
    "        denominator += len(para)\n",
    "    return denominator\n",
    "\n",
    "# Given a list of sets, each set containing words in a para, and a word_pair, calculates \n",
    "# the NPMI_similarity\n",
    "def NPMI_calculation(word_pair, brown_list, p_denominator):\n",
    "    x = word_pair[0]\n",
    "    y = word_pair[1]\n",
    "    p_x = calculate_p_word_numerator(x, brown_list)/p_denominator\n",
    "    p_y = calculate_p_word_numerator(y, brown_list)/p_denominator\n",
    "    p_x_y = calculate_p_cooccurrence_numerator(x,y, brown_list)/p_denominator\n",
    "    if p_x_y == 0:\n",
    "        return -1\n",
    "    return math.log(p_x*p_y,2)/math.log(p_x_y,2) - 1\n",
    "\n",
    "# Using functions defined above, creates NPMI_similarities dictionary\n",
    "brown_list = create_brown_list(brown)\n",
    "p_denominator = calculate_p_denominator(brown_list)\n",
    "for word_pair in final_gold_standard:\n",
    "    NPMI_similarities[word_pair] = NPMI_calculation(word_pair, brown_list, p_denominator)\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "print(NPMI_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(NPMI_similarities[('professor', 'doctor')] == -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** As PMI matrix is very sparse and can be approximated well by a dense representation via singular value decomposition (SVD), you will derive similarity scores using the Latent Semantic Analysis (LSA) method, i.e. apply SVD and truncate to get a dense vector representation of a word type and then calculate cosine similarity between the two vectors for each word pair. You can use the Distributed Semantics notebook as a starting point, but note that since you are interested here in word semantics, you will be constructing a matrix where the (non-sparse) rows correspond to words in the vocabulary, and the (sparse) columns correspond to the texts where they appear (this is the opposite of the notebook). Again, use the Brown corpus, in the same format as with PMI and document frequency. After you have a matrix in the correct format, use `truncatedSVD` in `sklearn` to produce dense vectors of length k = 500, and then use cosine similarity to produce similarities for your word pairs. \n",
    "\n",
    "When you are done, you should store the word pair and LSA-similarity mappings in a dictionary called *LSA_similarities*. You may check the section, <i>\"For your testing\"</i>, below for the expected *LSA_similarities*. \n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('bread', 'butter'): 0.3680537092209177, ('professor', 'doctor'): 0.04771843253684325, ('student', 'professor'): -0.025129221594411423, ('stock', 'egg'): -0.009191609752586765, ('money', 'cash'): 0.21502483127265923, ('king', 'queen'): 0.11820474502167592, ('bishop', 'rabbi'): 0.04344493710754035, ('football', 'basketball'): 0.17940389201651458, ('football', 'tennis'): -0.004167895189318334, ('alcohol', 'chemistry'): -0.010279893696664613, ('baby', 'mother'): 0.11258355803110169, ('car', 'automobile'): 0.1366546736211385, ('journey', 'voyage'): 0.04695542417698878, ('coast', 'shore'): 0.11680829726377648, ('brother', 'monk'): -0.030050372956540554, ('journey', 'car'): -0.008515484195502555, ('coast', 'hill'): 0.03743261517805603, ('forest', 'graveyard'): -0.03016800991246056, ('monk', 'slave'): 0.008835472508128885, ('coast', 'forest'): 0.0022361650913561635, ('psychology', 'doctor'): -0.02608434418569705, ('psychology', 'mind'): 0.008212150787906245, ('psychology', 'health'): -0.02034789739175676, ('psychology', 'science'): 0.018816600552343028, ('planet', 'moon'): 0.3247697629397515, ('planet', 'galaxy'): 0.028589927789756796}\n"
     ]
    }
   ],
   "source": [
    "# LSA_similarities stores the word pair and LSA similarity mappings\n",
    "LSA_similarities = {}\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# We have a dictionary of word to row, so we can use that to know which word \n",
    "# a certain row is referring to. We use this to access the appropriate vectors \n",
    "# represented by the rows, for any calculations.\n",
    "word_to_row = {}\n",
    "i = 0\n",
    "sparse_matrix = []\n",
    "\n",
    "# create our sparse matrix, with the rows being words, and columns being whether\n",
    "# that word is in a document or not.\n",
    "for word in doc_freq_dict:\n",
    "    row = []\n",
    "    word_to_row[word] = i\n",
    "    i += 1\n",
    "    # now we create that row, then append it to our sparse matrix.\n",
    "    for para in brown_list:\n",
    "        if word in para:\n",
    "            row.append(1)\n",
    "        else:\n",
    "            row.append(0)\n",
    "    sparse_matrix.append(row)\n",
    "    \n",
    "# now we convert the sparse matrix into numpy array, so we can \n",
    "# run the svd. \n",
    "sparse_matrix = np.array(sparse_matrix)\n",
    "\n",
    "# now we transform the sparse matrix into a lower rank matrix. \n",
    "svd = TruncatedSVD(n_components=500)\n",
    "matrix_lowrank = svd.fit_transform(sparse_matrix)\n",
    "\n",
    "# for each pair, we get the vector by referring to the row of the word.\n",
    "# we get the row of the word by referring to the word to row dictionary.\n",
    "\n",
    "# gets a magnitude of a vector, abstracted here so code is more readable\n",
    "# for those not familiar with random numpy functions. \n",
    "def magnitude(vec):\n",
    "    return np.linalg.norm(vec)\n",
    "\n",
    "# calculates cosine similarity\n",
    "def cosine_sim(v1,v2):\n",
    "    numerator = np.dot(v1,v2)\n",
    "    denominator = magnitude(v1)*magnitude(v2)\n",
    "    return numerator/denominator\n",
    "\n",
    "# creates LSA_similarities dictionary, with the word vectors from our lowrank matrix\n",
    "# and cosine similarities between the vectors for the scores.\n",
    "for word1, word2 in final_gold_standard:\n",
    "    word_vec_1 = matrix_lowrank[word_to_row[word1]]\n",
    "    word_vec_2 = matrix_lowrank[word_to_row[word2]]\n",
    "    LSA_similarities[(word1, word2)] = cosine_sim(word_vec_1, word_vec_2)\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "print(LSA_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(LSA_similarities[('professor', 'doctor')] > 0 and LSA_similarities[('professor', 'doctor')] < 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparison with the Gold Standard (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Instructions:** Finally, you should compare all the similarities you've created to the gold standard you loaded and filtered in the first step. For this, you can use the Pearson correlation co-efficient (`pearsonr`), which is included in scipy (`scipy.stats`). Be careful converting your dictionaries to lists for this purpose, the data for the two datasets needs to be in the same order for correct comparison using correlation. Write a general function, then apply it to each of the similarity score dictionaries.\n",
    "\n",
    "When you are done, you should put the result in a dictionary called *pearson_correlations* (use the keys: 'lin', 'NPMI', 'LSA'). You may check the section, <i>\"For your testing\"</i>, below for the expected *pearson_correlations*. \n",
    "\n",
    "<b>Hint:</b> All of the methods used here should be markedly above 0, but also far from 1 (perfect correlation); if you're not getting reasonable results, go back and check your code for bugs!  \n",
    "\n",
    "(1 mark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lin': 0.48165028483571143, 'LSA': 0.39775264787480963, 'NPMI': 0.39325397087988434}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# pearson_correlations stores the pearson correlations with the gold standard of 'lin', 'NPMI', 'LSA'\n",
    "pearson_correlations = {}\n",
    "\n",
    "###\n",
    "# Your answer BEGINS HERE\n",
    "###\n",
    "\n",
    "# to ensure the entries in each array correspond to the same word, we will iterate through\n",
    "# the gold standard dictionary, get that pair, and populate all score arrays.\n",
    "num_pairs = len(final_gold_standard)\n",
    "\n",
    "lin_scores = np.zeros(num_pairs)\n",
    "NPMI_scores = np.zeros(num_pairs)\n",
    "LSA_scores = np.zeros(num_pairs)\n",
    "final_gold_standard_scores = np.zeros(num_pairs)\n",
    "\n",
    "i = 0\n",
    "for pair in final_gold_standard:\n",
    "    final_gold_standard_scores[i] = final_gold_standard[pair]\n",
    "    NPMI_scores[i] = NPMI_similarities[pair]\n",
    "    lin_scores[i] = lin_similarities[pair]\n",
    "    LSA_scores[i] = LSA_similarities[pair]\n",
    "    i += 1\n",
    "\n",
    "# now with all our score arrays, we can calculate correlation an dput it into pearson correlations\n",
    "# dictionary. We only take the 0th element of the return tuple, as we are not interested in the p-value,\n",
    "# just the coefficient score.\n",
    "pearson_correlations['lin'] = pearsonr(lin_scores, final_gold_standard_scores)[0]\n",
    "pearson_correlations['LSA'] = pearsonr(LSA_scores, final_gold_standard_scores)[0]\n",
    "pearson_correlations['NPMI'] = pearsonr(NPMI_scores, final_gold_standard_scores)[0]\n",
    "###\n",
    "# Your answer ENDS HERE\n",
    "###\n",
    "\n",
    "print(pearson_correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For your testing:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(pearson_correlations['lin'] > 0.4 and pearson_correlations['lin'] < 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge yourself: Improving the correlation (This part will NOT be marked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to derive a similarity score from word2vec vectors, using the Gensim interface, and compare it with the similarity scores you've created and the gold standard. Check the Gensim word2vec tutorial for details on the API: https://radimrehurek.com/gensim/models/word2vec.html. Again, you should use the Brown for this, but for word2vec you don't need to worry about paragraphs: feel free to train your model at the sentence level instead. Your vectors should have the same number of dimensions as LSA (500), and you need to run for 50 iterations. This may take a while (several minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A final word\n",
    "\n",
    "Normally, we would not use a corpus as small as the Brown for the purposes of building distributional word vectors. Also, note that filtering our test set to just words we are likely to do well on would typically be considered cheating."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
